# https://github.com/triton-inference-server/common/blob/main/protobuf/model_config.proto
name: "{{model_name}}"
backend: "python"
max_batch_size: 0
input [
  {
    name: "image"
    data_type: TYPE_UINT8
    dims: [ 3, -1, -1 ]
  }
]
output [
  {
    name: "score"
    data_type: TYPE_FP32
    dims: [ 1 ]
  },
  {
    name: "confidence"
    data_type: TYPE_FP32
    dims: [ 1 ]
  },
  {
    name: "probability"
    data_type: TYPE_FP32
    dims: [ 1 ]
    label_filename: "binary_labels.txt"
  }
]
model_warmup: [
  {
    name: "warmup_with_zero_image"
    batch_size: 1
    inputs {
      key: "image"
      value {
        dims: [ 3, 512, 300 ]
        data_type: TYPE_UINT8
        zero_data: true
      }
    }
  }
]