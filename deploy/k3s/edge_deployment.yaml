# Required runtime class for GPU use in k3s
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia
---
apiVersion: v1
kind: Service
metadata:
  name: edge-endpoint-service
spec:
  selector:
    app: edge-logic-server
  ports:
  - protocol: TCP
    # Service port for NGINX
    port: 6717
    nodePort: 30101
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: edge-endpoint
  labels:
    app: edge-endpoint
spec:
  replicas: 1
  selector:
    matchLabels:
      app: edge-logic-server
  template:
    metadata:
      labels:
        app: edge-logic-server
    spec:
      # This service account is used by the edge logic to access the Kubernetes API
      # from within the pod. See deploy/k3s/service_account.yaml for more details
      serviceAccountName: edge-endpoint-service-account
      containers:
      - name: edge-endpoint
        image: 723181461334.dkr.ecr.us-west-2.amazonaws.com/edge-endpoint:tyler-fix-patience-time-0d64ab0df-dirty-19cac12e4adca89
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 6717
        env:
        - name: LOG_LEVEL
          value: "DEBUG"
        - name: GROUNDLIGHT_API_TOKEN
          valueFrom:
            secretKeyRef:
              name: groundlight-secrets
              key: api-token
        volumeMounts:
        - name: edge-config-volume
          # This is a path inside the container not the host
          mountPath: /etc/groundlight
        - name: inference-deployment-template-volume
          mountPath: /etc/groundlight
        - name: model-repo
          mountPath: /mnt/models
      imagePullSecrets:
      - name: registry-credentials
      volumes:
      - name: edge-config-volume
        configMap:
          name: edge-config
      - name: inference-deployment-template-volume
        configMap:
          name: inference-deployment-template
      - name: model-repo
        hostPath:
          # A hostPath volume mounts a file or directory from the host node's filesystem into your Pod
          # This simiplifies things a lot, but only really works for single-node clusters.
          # TODO: check out k3s local path provisioner: https://docs.k3s.io/storage#setting-up-the-local-storage-provider
          path: /home/ubuntu/ptdev/zuuul2/predictors/serving/model_repository
          type: DirectoryOrCreate
